syntax = "proto3";
option optimize_for = LITE_RUNTIME;
// all the matrix are stored in row-major order,
// plz see https://en.wikipedia.org/wiki/Row-_and_column-major_order for details

// the definition of "Multi-Head Attention", "Scaled Dot-Product Attention" and
// "Feed-Forward Networks"
// plz see https://arxiv.org/abs/1706.03762 for details

message VitEncoderLayer {
  // layer norm before "Multi-Head Attention"
  repeated float multihead_norm_scale = 1; // [hidden_size]
  repeated float multihead_norm_bias = 2; // [hidden_size]

  // "Multi-Head Attention" linearly project weights kernel for query, key,
  // value,
  // before "Scaled Dot-Product Attention, with shape (hidden_size,
  // hidden_size*3)
  // is built by numpy.concatenate((query_kernel, key_kernel, value_kernel),
  // axis=1)
  // perform numpy.dot(input, multihead_project_kernel_qkv) will get the [query,
  // key, value] of
  // "Scaled Dot-Product Attention"
  repeated float multihead_project_kernel_qkv = 3; // [hidden_size, 3, hidden_size]
  repeated float multihead_project_bias_qkv = 4; // [3, hidden_size]
  repeated float multihead_project_kernel_output = 5; // [hidden_size, hidden_size]
  repeated float multihead_project_bias_output = 6; // [hidden_size]

  // layer norm before "Feed-Forward Networks"
  repeated float ffn_norm_scale = 7; // [hidden_size]
  repeated float ffn_norm_bias = 8; // [hidden_size]

  // "Feed-Forward Networks"
  repeated float ffn_first_kernel = 9; // [hidden_size, inner_size]
  repeated float ffn_first_bias = 10; // [inner_size]
  repeated float ffn_second_kernel = 11; // [inner_size, hidden_size]
  repeated float ffn_second_bias = 12; // [hidden_size]
}

message VitEmbeddingLayer {
  // weight and bias of convolution in patch embedding
  repeated float conv_weight = 1; // [hidden_size, channel_input, patch_size, patch_size]
  repeated float conv_bias = 2; // [hidden_size]
  // learnable position embedding
  repeated float position_embedding = 3; // [max_seq_len, hidden_size]
  repeated float cls_embedding = 4; // [hidden_size]
}

message VitModelConf {
  int32 head_num = 1;
  bool use_gelu = 2; // use gelu for activation otherwise relu
  int32 image_size = 3; // width of input image
  int32 patch_size = 4; //width of patch and convolution kernel
}

message Vit {
  VitEmbeddingLayer src_embedding = 1;
  repeated VitEncoderLayer encoder_stack = 2;
  VitModelConf model_conf = 3;
}
